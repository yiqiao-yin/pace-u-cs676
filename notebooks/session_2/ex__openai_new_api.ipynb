{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6VQIukZ3gEc",
        "outputId": "5d5e156c-0ddc-4eca-fe92-a76a5772a40a"
      },
      "outputs": [],
      "source": [
        "! pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dkYHOhwK3hFk"
      },
      "outputs": [],
      "source": [
        "key = \"sk-your-api-key-here\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "mExDz_wlKAQJ"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "JX91d4Ia3iBx"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI(api_key=OPENAI_API_KEY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "2Nit6Onb3xx5"
      },
      "outputs": [],
      "source": [
        "result_from_news = \"\"\"\n",
        "Title: DeepSeek Panic Live Updates: Nvidia Stock Makes History ...\n",
        "Link: https://www.forbes.com/sites/dereksaul/2025/01/28/deepseek-panic-live-updates-nvidia-stock-makes-history-again-with-260-billion-rebound/\n",
        "\n",
        "Title: NVIDIA Corp. Stock Quote (U.S.: Nasdaq) - NVDA\n",
        "Link: https://www.marketwatch.com/investing/stock/nvda\n",
        "\n",
        "Title: NASDAQ:NVDA Stock Price - Nvidia - TradingView\n",
        "\"\"\"\n",
        "\n",
        "engineered_content = f\"\"\"\n",
        "    user query: nvidia stock price\n",
        "    here's some additional info regarding user query:\n",
        "    {result_from_news}\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "    {\"role\": \"user\", \"content\": engineered_content}\n",
        "  ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "ZVyYYI_Y3y3G",
        "outputId": "f9b9a03f-759b-4c31-e3c5-e41be581213c"
      },
      "outputs": [],
      "source": [
        "response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KG1LwBVYPR-u"
      },
      "outputs": [],
      "source": [
        "def call_chatgpt(question: str) -> str:\n",
        "    \"\"\"\n",
        "    Calls the GPT model using the provided client to generate a response to a given question.\n",
        "\n",
        "    The function takes a question as input and interacts with an OpenAI GPT model through the client's chat\n",
        "    completion API. If there is any exception during the API call, it catches the exception and provides a\n",
        "    default error response.\n",
        "\n",
        "    Parameters:\n",
        "    question (str): The user's question that needs to be sent to the GPT model.\n",
        "\n",
        "    Returns:\n",
        "    str: The generated response from the GPT model. In case of an error, a default error message is returned.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Generate a response using the GPT model specified, with a fixed system role message followed by the user's question.\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "                {\"role\": \"user\", \"content\": question},\n",
        "            ],\n",
        "        )\n",
        "        # Extract the content of the message received from the GPT model.\n",
        "        output = response.choices[0].message.content\n",
        "    except Exception as e:\n",
        "        # Print the exception and return a default error message if any exception occurs.\n",
        "        print(e)\n",
        "        output = \"Sorry, I couldn't get an answer for that.\"\n",
        "\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "qiAVVPXsPf1w",
        "outputId": "1d3dfc07-8a2c-4779-b39b-fbc21d3136fa"
      },
      "outputs": [],
      "source": [
        "call_chatgpt(\"tell me a joke\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJdTB3QKPgl7"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
