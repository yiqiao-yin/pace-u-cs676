{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WwYT86ib1cS4"
      },
      "source": [
        "## Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3zNkeOrPgcQ",
        "outputId": "4a367524-3074-4849-b7b6-92f9225d390f"
      },
      "outputs": [],
      "source": [
        "! pip install wyn-voice pyautogen pydub"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BlcAq2Y2Jnf"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1yeqHIdIP0f1",
        "outputId": "8f01dea2-d90f-4912-ddbf-d62f9448460d"
      },
      "outputs": [],
      "source": [
        "from wyn_voice.chat import *\n",
        "from autogen import ConversableAgent\n",
        "from pydub import AudioSegment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "0GU8Cx9IP2iF"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "F0Rg5MbBP8VF"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "from autogen.coding import CodeBlock, LocalCommandLineCodeExecutor\n",
        "\n",
        "work_dir = Path(\"coding\")\n",
        "work_dir.mkdir(exist_ok=True)\n",
        "executor = LocalCommandLineCodeExecutor(work_dir=work_dir)\n",
        "\n",
        "# Create an agent with code executor configuration.\n",
        "code_executor_agent = ConversableAgent(\n",
        "    \"code_executor_agent\",\n",
        "    llm_config=False,  # Turn off LLM for this agent.\n",
        "    code_execution_config={\"executor\": executor},  # Use the local command line code executor.\n",
        "    human_input_mode=\"NEVER\",  # Always take human input for this agent for safety.\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVHrH38dQDW1"
      },
      "source": [
        "## Configure and Run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "cellView": "form",
        "id": "id65LfbkQCC2"
      },
      "outputs": [],
      "source": [
        "# @title Choose a bot\n",
        "\n",
        "# Reinitiate bot\n",
        "# Example usage\n",
        "assistant_v1 = ChatBot(\n",
        "    api_key=OPENAI_API_KEY,\n",
        "    protocol=\"\"\"\n",
        "    You are a helpful assistant.\n",
        "\n",
        "    If user asks you python related question, you will ask question back and clarify it.\n",
        "    If all makes sense, you will write the python code for user.\n",
        "    If the python code is written from before, ask user whether they want to execute it.\n",
        "    \"\"\"\n",
        ")\n",
        "assistant_v2 = ChatBot(\n",
        "    api_key=OPENAI_API_KEY,\n",
        "    protocol=\"\"\"\n",
        "    You are a helpful assistant. You are an expert to recommend life style choices.\n",
        "    \"\"\"\n",
        ")\n",
        "assistant_v3 = ChatBot(\n",
        "    api_key=OPENAI_API_KEY,\n",
        "    protocol=\"\"\"\n",
        "    You are a therapist.\n",
        "\n",
        "    You are an expert at guiding people through mental health stresses and work situations.\n",
        "    You are a good listener and you take the patients (user) complain and try to understand it.\n",
        "    When user ask, you may suggest some life style choices to the user based on the user's complain.\n",
        "    \"\"\"\n",
        ")\n",
        "assistant_v4 = ChatBot(\n",
        "    api_key=OPENAI_API_KEY,\n",
        "    protocol=\"\"\"\n",
        "    You are a McDonald drivethrough service assistant.\n",
        "\n",
        "    Here's a menu for the day:\n",
        "\n",
        "    | Item                       | Price  | Calories |\n",
        "    |----------------------------|--------|----------|\n",
        "    | Big Mac                    | $5.99  | 550      |\n",
        "    | Quarter Pounder with Cheese| $6.49  | 750      |\n",
        "    | McChicken                  | $3.29  | 400      |\n",
        "    | Filet-O-Fish               | $4.99  | 390      |\n",
        "    | French Fries (Medium)      | $2.99  | 340      |\n",
        "    | Chicken McNuggets (10 pcs) | $5.49  | 480      |\n",
        "    | McDouble                   | $2.99  | 390      |\n",
        "    | Egg McMuffin               | $3.99  | 300      |\n",
        "    | Sausage Biscuit            | $2.79  | 460      |\n",
        "    | Apple Pie                  | $1.49  | 240      |\n",
        "\n",
        "    You are designed to serve the cutomer with the best price and calories combination.\n",
        "\n",
        "    User will ask you some questions and price and calories.\n",
        "\n",
        "    Ask user if they are ready to confirm the order.\n",
        "\n",
        "    If user is ready to confirm the order, write a python code for the order. The python code saves the order in a csv file.\n",
        "    If user is not ready to confirm the order, ask user if there's anything to add.\n",
        "\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "# Choose assistant\n",
        "value = \"Lifestyle Helper\" # @param [\"Coding Helper\", \"Lifestyle Helper\", \"Therapist\", \"Drivethrough\"]\n",
        "\n",
        "def set_assistant():\n",
        "    if value == \"Coding Helper\":\n",
        "        assistant = assistant_v1\n",
        "    elif value == \"Lifestyle Helper\":\n",
        "        assistant = assistant_v2\n",
        "    elif value == \"Drivethrough\":\n",
        "        assistant = assistant_v3\n",
        "    else:\n",
        "        assistant = assistant_v4\n",
        "    audio_processor = AudioProcessor(bot=assistant)\n",
        "\n",
        "    return assistant, audio_processor\n",
        "\n",
        "assistant, audio_processor = set_assistant()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "id": "ApD1Q61yQOW2",
        "outputId": "2b1b37f4-3ede-46d4-93d7-8a2ce3f2d8aa"
      },
      "outputs": [],
      "source": [
        "# @title Talk to JARVIS\n",
        "\n",
        "greetings = False\n",
        "if greetings:\n",
        "    # Greetings\n",
        "    response_short = \"Hi, welcome to our store! How may I help you?\"\n",
        "    print(\"ü§ñ Bot: \", response_short)\n",
        "\n",
        "    # Audio output\n",
        "    output_file_path = audio_processor.text_to_voice(response_short)\n",
        "    audio = AudioSegment.from_file(output_file_path)\n",
        "    audio_length = len(audio) / 1000.0 + 1\n",
        "    print(\"‚è≥ Audio lag: \", audio_length)\n",
        "\n",
        "prompt = \"\"\n",
        "response = \"\"\n",
        "reply = \"\"\n",
        "audio_length = 0\n",
        "while \"exit\" not in prompt.lower():\n",
        "    # User\n",
        "    prompt = audio_processor.voice_to_text(sec=4)\n",
        "    print(\"ü§î User: \", prompt)\n",
        "\n",
        "    # Command [conditional]\n",
        "    if \"execute\" in prompt.lower():\n",
        "        message_with_code_block = f\"\"\"This is a message with code block.\n",
        "        {response}\n",
        "        \"\"\"\n",
        "\n",
        "        # Generate a reply for the given code.\n",
        "        reply = code_executor_agent.generate_reply(messages=[{\"role\": \"user\", \"content\": message_with_code_block}])\n",
        "        print(\"üíª Executing....\")\n",
        "        print(reply)\n",
        "\n",
        "        # Bot\n",
        "        try:\n",
        "            response = assistant.generate_response(\n",
        "                f\"\"\"User has provided the prompt: {prompt}\n",
        "                And previous we have an answer: {response}\n",
        "\n",
        "                Now that the code finished executing. Here's the result: {reply}.\n",
        "\n",
        "                Summarize the result and ask for another question or task. \"\"\"\n",
        "            )\n",
        "            print(\"ü§ñ Bot: \", response)\n",
        "        except:\n",
        "            assistant, audio_processor = set_assistant()\n",
        "            response = assistant.generate_response(\n",
        "                f\"\"\"User has provided the prompt: {prompt}\n",
        "                And previous we have an answer: {response}\n",
        "\n",
        "                Now that the code finished executing. Here's the result: {reply}.\n",
        "\n",
        "                Summarize the result and ask for another question or task. \"\"\"\n",
        "            )\n",
        "            print(\"ü§ñ Bot: \", response)\n",
        "\n",
        "    else:\n",
        "        # Bot\n",
        "        try:\n",
        "            response = assistant.generate_response(prompt)\n",
        "            print(\"ü§ñ Bot: \", response)\n",
        "        except:\n",
        "            assistant, audio_processor = set_assistant()\n",
        "            response = assistant.generate_response(prompt)\n",
        "            print(\"ü§ñ Bot: \", response)\n",
        "\n",
        "    # Audio\n",
        "    if \"\\n\\n```python\" in response.lower() or len(response) > 500:\n",
        "        response_short = assistant.generate_response(f\"Summarize the following in 1-2 sentences: {response}\")\n",
        "    else:\n",
        "        response_short = response\n",
        "\n",
        "    # Audio output\n",
        "    output_file_path = audio_processor.text_to_voice(response_short)\n",
        "    audio = AudioSegment.from_file(output_file_path)\n",
        "    audio_length = len(audio) / 1000.0 + 1\n",
        "    print(\"‚è≥ Audio lag: \", audio_length)\n",
        "\n",
        "    # Wait from last round\n",
        "    time.sleep(audio_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2uG5ibRW-THa"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "WwYT86ib1cS4",
        "-BlcAq2Y2Jnf"
      ],
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
